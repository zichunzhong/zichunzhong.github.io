<blockquote style="margin:0 0 0 40px;border:none;padding:0px">
<div style="text-align:center;margin:0px 200px 0px 200px"><font size="5"><span style="line-height:1.5;color:rgb(0,0,0);font-family:Times New Roman,serif;background-color:transparent"><b>NSF: Elements: MVP: Open-Source AI-Powered MicroVessel Processor for Next-Generation Vascular Imaging Data (# 2311245)</b></font></div>
<div style="text-align:center;margin:0px 200px 0px 200px"><br>
</div>
<div style="text-align:center;margin:0px 200px 0px 200px"><font size="3"><span style="line-height:1.5;color:rgb(0,0,0);font-family:Times New Roman,serif;background-color:transparent"><b>Zichun Zhong (PI), Jing Hua (Co-PI)</b></font></div>
<div style="text-align:center;margin:0px 200px 0px 200px"><font size="3"><span style="line-height:1.5;color:rgb(0,0,0);font-family:Times New Roman,serif;background-color:transparent">Wayne State University, Detroit, Michigan</font></div>
<div style="text-align:center;margin:0px 200px 0px 200px"><font size="3"><span style="line-height:1.5;color:rgb(0,0,0);font-family:Times New Roman,serif;background-color:transparent">zichunzhong@wayne.edu, jinghua@wayne.edu</font></div>
</blockquote>
<div style="text-align:center;margin:0px 200px 0px 200px"><br>
</div>
<div style="text-align:center;margin:0px 200px 0px 200px">
<div style="display:block;text-align:center;margin-right:auto;margin-left:auto">
<div style="display:block;text-align:center;margin-right:auto;margin-left:auto"><br>
</div>
<div style="display:block;text-align:center;margin-right:auto;margin-left:auto">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="pic/MVP_teaser.png" imageanchor="1"><img border="0" src="pic/MVP_teaser.png" style="width:70%"></a></div>
</div>
</div>
<div style="text-align:left;margin:0px 200px 0px 200px;border-style:none none solid;border-bottom-color:windowtext;border-bottom-width:1.5pt;padding:0in 0in 1pt"><br>
</div>
<div style="text-align:left;margin:0px 200px 0px 200px;border-style:none none solid;border-bottom-color:windowtext;border-bottom-width:1.5pt;padding:0in 0in 1pt">
<div><b style="line-height:1.5;text-align:left;background-color:transparent"><font color="#000000" size="3"><font face="Times New Roman, serif"><u>
</u></font></font></b></div>
<p style="text-align:left"><b><span style="font-family:Times New Roman,serif"><font color="#000000" size="3"><u>Abstract:</u></font></span></b></p>	  
<ul style="font-family:Times New Roman,serif;font-size:medium;line-height:normal;color:rgb(0,0,0);margin-top:0in">
<span style="text-align:justify;background-color:transparent"><font></font><font color="#000000">Effectively acquiring and processing complicated microstructures and their morphology become increasingly important in scientific and engineering discoveries. A growing body of evidence in animal and human studies shows that micro-cerebrovascular abnormalities are the real source of many neurologic disorders and vascular diseases. Therefore, there is an urgent need for better detection and understanding of vascular characteristics in vivo at the micro-level. However, the existing techniques and software solutions are developed based on general-scale medical images for processing macro-level organs and tissues, not applicable to the challenging next-generation vascular imaging data and micro-level vasculature. Furthermore, they are difficult to be customized to specific scientific microvascular imaging applications for domain developers. The overall objective of this project is to design and develop a rigorous, scalable, intelligent, and comprehensive data and software infrastructure, MicroVessel Processor (MVP), which supports and sustains advancements of understanding and analyzing the complicated 3D microvascular networks, provides services to a large community, and fosters continuous innovation in the multidisciplinary domains.<br><br>
This project integrates new paradigm of data-driven 3D microvascular discovery - generate new knowledge and understanding and accelerate discovery and innovation via the advanced software cyberinfrastructure, along with use-case driven functional applications and evaluations. The capabilities of the newly developed AI-based high-fidelity 3D image enhancement, 3D geometric segmentation / extraction, reconstruction, and analytics techniques are integrated in the MVP system as the core modules in the software infrastructure. The MVP database including a large number of subjects with varying anatomical shapes, morphological features, and different data modalities is collected and constructed as the infrastructure (i.e., knowledgebase), which provides the knowledge for 3D microvascular networks tracking and analysis. The MVP system is designed and built based on an open-source and drag-drop real-time application system, in order to reduce both human labors and computation costs, accelerate the speed and efficiency of re-development and extensibility. This unique framework supports a wide adoption in microvasculature analytics in biomedical engineering, big-data neuroscience, and AI-based clinical diagnosis.</font></span>
  
</ul>
<div><span style="text-align:left;line-height:24px;background-color:transparent"><font color="#000000" face="Times New Roman, serif" size="3"><b><br>
</b></font></span></div>
<div><br>
</div>
</div>
<div style="text-align:center;margin:0px 200px 0px 200px;">
<p style="text-align:left"><b><span style="font-family:Times New Roman,serif"><font color="#000000" size="3"><u>Source Code Release:</u></font></span></b></p>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">JointVesselNet and VC-Net on 3D Microstructure Extraction: [<a href="https://github.com/SuperStacie/JointVesselNet_VC-Net">Code</a>]</li></ul>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Joint Shape-Image Latent Embedding on Simultaneous Multimodal 3D Shape Generation: [<a href="https://github.com/akomarichev/joint_latent_space">Code</a>]</li></ul>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">NASM: Neural Anisotropic Surface Meshing: [<a href="https://github.com/Hongbo-huayra/NASM_Neural_Anisotropic_Surface_Meshing">Code</a>]</li></ul>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Consolidating Weak Features in High-Quality Mesh Simplification: [<a href="https://github.com/Xrvitd/CWF">Code</a>]</li></ul>
	
<div style="border:none;border-bottom:solid windowtext 1.5pt;padding:0in 0in 1.0pt 0in"><br>
</div>
<p style="text-align:left"><b><span style="font-family:Times New Roman,serif"><font color="#000000" size="3"><u>Dataset Release:</u></font></span></b></p>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Magnetic Resonance Angiography (MRA) Microvessel Datasets: [<a href="https://drive.google.com/drive/folders/1cpgrnQWG7cfyhetSCODORkqMe_ohGVBT?usp=sharing">Data</a>]</li></ul>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">MICRO-MRI Datasets: [<a href="https://drive.google.com/drive/folders/1Wz2ymerdJsPZKgNZgX5VVNMNtzzIPg28?usp=sharing">Data</a>]</li></ul>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Abnormal MICRO-MRI Datasets: [<a href="https://drive.google.com/drive/folders/1Zb-k5a78uyRJgCD5K6A34m9eG1COKXAc?usp=sharing">Data</a>]</li></ul>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Hippocampus Datasets: [<a href="https://drive.google.com/drive/folders/13CGAVAQ2a_G3krfxFyAIrJQA4e-fkz_6?usp=sharing">Data</a>]</li></ul>
	
<div style="border:none;border-bottom:solid windowtext 1.5pt;padding:0in 0in 1.0pt 0in"><br>
</div>
<p style="text-align:justify;text-justify:inter-ideograph;line-height:normal"><a name="OLE_LINK1"><b><u><span style="font-family:Times New Roman,serif"><font color="#000000">Selected Publications: </font></span></u></b></a></p>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Haikuan Zhu, Hongbo Li, Hsueh-Ti Derek Liu, Wenping Wang, Jing Hua, Zichun Zhong, "Designing 3D Anisotropic Frame Fields with Odeco Tensors," in <em>ACM Transactions on Graphics (SIGGRAPH 2025)</em>, Vol. 44, Issue 4, 2025. [<a href="https://arxiv.org/abs/2505.05639">Paper</a>]</li></ul>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Yifan Wang, Haikuan Zhu, Hongbo Li, Guoli Yan, Sagar Buch, Ying Wang, Ewart Mark Haacke, Jing Hua, Zichun Zhong, "ROSE: Multi-Level Super-Resolution-Oriented Semantic Embedding for 3D Microvasculature Segmentation from Low-Resolution Images," in <em>Neurocomputing</em>, Vol. 599, 128038, 2024.
[<a href=papers/ROSE_main.pdf>Paper</a>] [<a href=papers/ROSE_supp.pdf>Supplement</a>]</li></ul>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Michael Hua, Junjie Wu, Zichun Zhong, "Multi-Scale Knowledge Transfer Vision Transformer for 3D Vessel Shape Segmentation," in <em>Computers & Graphics</em>, Vol. 122, 103976, 2024. [<a href=papers/KT-ViT.pdf>Paper</a>]</li></ul>	
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Hongbo Li, Haikuan Zhu, Sikai Zhong, Ningna Wang, Cheng Lin, Xiaohu Guo, Shiqing Xin, Wenping Wang, Jing Hua, Zichun Zhong, "NASM: Neural Anisotropic Surface Meshing,"  in <em>SIGGRAPH Asia (Conference Paper)</em>, 2024. [<a href="https://arxiv.org/abs/2410.23109">Paper</a>]</li></ul>		
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Rui Xu, Longdu Liu, Ningna Wang, Shuangmin Chen, Shiqing Xin, Xiaohu Guo, Zichun Zhong, Taku Komura, Wenping Wang, Changhe Tu, "CWF: Consolidating Weak Features in High-quality Mesh Simplification," in <em>ACM Transactions on Graphics (SIGGRAPH 2024)</em>. [<a href="https://arxiv.org/abs/2404.15661">Paper</a>]</li></ul>		
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Artem Komarichev, Jing Hua, Zichun Zhong, "DiffSVR: Differentiable Neural Implicit Surface Rendering for Single-View Reconstruction with Highly Sparse Depth Prior," in <em>Computer-Aided Design</em>, Vol. 164, 103604, 2023. [<a href=papers/DiffSVR_CAD2023.pdf>Paper</a>] [<a href="https://waynestateprod-my.sharepoint.com/:b:/g/personal/fy7555_wayne_edu/EWV9oiBPUPJKjZs02eON5-8Bm7y_dFDVdn9JV_hbLf92ig?e=8YVLBc">Supplement</a>]</li></ul>	
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Artem Komarichev, Jing Hua, Zichun Zhong, "Learning Geometry-Aware Joint Latent Space for Simultaneous Multimodal Shape Generation," in <em>Computer Aided Geometric Design (GMP 2022)</em>, Vol. 93, 102076, 2022. [<a href=papers/JointLatent_CAGD2022.pdf>Paper</a>] [<a href=papers/JointLatent_Supp_CAGD2022_LR.pdf>Supplement</a>]</li></ul>	
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Yifan Wang, Guoli Yan, Haikuan Zhu, Sagar Buch, Ying Wang, Ewart Mark Haacke, Jing Hua, Zichun Zhong, "VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data," in <em>IEEE Transactions on Visualization and Computer Graphics (TVCG)</em>, Vol. 27, No. 2, pp. 1301 - 1311, 2021. [<a href=papers/VCNet_VIS2020.pdf>Paper</a>] [<a href=papers/VCNet_supp_VIS2020.pdf>Supplement</a>]</li></ul>		
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Yifan Wang, Guoli Yan, Haikuan Zhu, Sagar Buch, Ying Wang, Ewart Mark Haacke, Jing Hua, Zichun Zhong, "JointVesselNet: Joint Volume-Projection Convolutional Embedding Networks for 3D Cerebrovascular Segmentation," in <em>The International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2020. [<a href=papers/JointVesselNet_MICCAI2020.pdf>Paper</a>]</li></ul>
<div style="text-align:left"><ul><li><style="color:rgb(0,0,0);font-family:times new roman,serif;font-size:medium;line-height:1.5;background-color:transparent">Yifan Wang, Zichun Zhong, Jing Hua, "DeepOrganNet: On-the-Fly Reconstruction and Visualization of 3D / 4D Lung Models from Single-View Projections by Deep Deformation Network," in <em>IEEE Transactions on Visualization and Computer Graphics (TVCG)</em>, Vol. 26, No. 1, pp. 960 - 970, 2020. [<a href="http://zzhong.eng.wayne.edu/_resources/pdfs/DeepOrganNet_TVCG2019.pdf">Paper</a>]</li></ul>

<div style="border:none;border-bottom:solid windowtext 1.5pt;padding:0in 0in 1.0pt 0in"><br>
</div>
<p style="text-align:justify;text-justify:inter-ideograph;line-height:normal"><a name="OLE_LINK1"><b><u><span style="font-family:Times New Roman,serif"><font color="#000000">Acknowledgement: </font></span></u></b></a></p>
<ul style="font-family:Times New Roman,serif;font-size:medium;line-height:normal;color:rgb(0,0,0);margin-top:0in">
<span style="text-align:justify;background-color:transparent"><font></font><font color="#000000">This project is based upon work supported by the National Science Foundation under Grant No. OAC-2311245.</font></span>

<div style="font-family:Times New Roman,serif;font-size:medium;line-height:normal;text-align:justify"><font color="#000000"><br>
</font></div>
<div style="text-align:justify">
<div style="font-family:Times New Roman,serif;font-size:medium;line-height:normal;text-align:center;border-style:none none solid;border-bottom-color:windowtext;border-bottom-width:1.5pt;padding:0in 0in 1pt"><br>
</div>
<!-- <div style="text-align:center;border-style:none none solid;border-bottom-color:windowtext;border-bottom-width:1.5pt;padding:0in 0in 1pt">
<div style="font-family:Open Sans;font-size:14px;line-height:21px"><br>
</div> -->

<br>
<tr> 
	<td height="21"><strong>Last Update: September 2025</strong></td>
</tr>
